"use client";

import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";
import Link from "next/link";
import { useRouter } from "next/navigation";

export default function Home() {
  const [installPrompt, setInstallPrompt] = useState(null);
  const [isInstalled, setIsInstalled] = useState(false);
  const [showPopup, setShowPopup] = useState(false);
  const [loading, setLoading] = useState(false);
  const [modelsLoaded, setModelsLoaded] = useState(false);
  const [videoReady, setVideoReady] = useState(false);
  const videoRef = useRef(null);
  const detectTimer = useRef(null);
  const runningDetection = useRef(false);
  const router = useRouter();

  const handleClose = () => setShowPopup(false);

  // Load face-api models (once)
  useEffect(() => {
    let cancelled = false;
    (async () => {
      const MODEL_URL = "/models";
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
      ]);
      if (!cancelled) {
        setModelsLoaded(true);
        console.log("‚úÖ Face-api models loaded");
      }
    })();
    return () => {
      cancelled = true;
    };
  }, []);

  // Start video stream
  useEffect(() => {
    let currentStream;
    (async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "user",
            width: { ideal: 640 },
            height: { ideal: 480 },
            frameRate: { ideal: 30, max: 30 },
          },
          audio: false,
        });
        currentStream = stream;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.onloadedmetadata = () => {
            setVideoReady(true);
            videoRef.current?.play?.();
          };
        }
      } catch (err) {
        console.error("üé• Camera error:", err);
        alert("Could not access camera. Please allow camera permissions.");
      }
    })();

    // Cleanup camera on unmount
    return () => {
      if (detectTimer.current) clearInterval(detectTimer.current);
      if (currentStream) {
        currentStream.getTracks().forEach((t) => t.stop());
      }
    };
  }, []);

  // PWA install prompt
  useEffect(() => {
    const handleBeforeInstallPrompt = (e) => {
      e.preventDefault();
      setInstallPrompt(e);
    };
    const handleAppInstalled = () => setIsInstalled(true);

    window.addEventListener("beforeinstallprompt", handleBeforeInstallPrompt);
    window.addEventListener("appinstalled", handleAppInstalled);

    if (window.matchMedia("(display-mode: standalone)").matches) {
      setIsInstalled(true);
    }

    return () => {
      window.removeEventListener(
        "beforeinstallprompt",
        handleBeforeInstallPrompt
      );
      window.removeEventListener("appinstalled", handleAppInstalled);
    };
  }, []);

  const handleInstall = () => {
    if (installPrompt) {
      installPrompt.prompt();
      installPrompt.userChoice.then((choice) => {
        if (choice.outcome === "accepted") {
          setInstallPrompt(null);
          setIsInstalled(true);
        }
      });
    }
  };

  const captureImage = () => {
    const canvas = document.createElement("canvas");
    const video = videoRef.current;
    canvas.width = video.videoWidth || 640;
    canvas.height = video.videoHeight || 480;
    const ctx = canvas.getContext("2d");
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
    return canvas.toDataURL("image/jpeg", 0.9);
  };

  // Average N descriptors across a short time to stabilize identity
  const getAveragedDescriptor = async (samples = 3, gapMs = 150) => {
    const options = new faceapi.TinyFaceDetectorOptions({
      inputSize: 224, // better accuracy than 160
      scoreThreshold: 0.6,
    });

    const vecs = [];

    for (let i = 0; i < samples; i++) {
      const det = await faceapi
        .detectSingleFace(videoRef.current, options)
        .withFaceLandmarks()
        .withFaceDescriptor();

      if (!det) return { ok: false, reason: "no-face" };

      // Require strong detection confidence
      if (det.detection.score < 0.75) {
        return { ok: false, reason: "low-confidence" };
      }

      // Require sufficiently large face to avoid background/mini faces
      const box = det.detection.box;
      const minSize = Math.min(
        videoRef.current?.videoWidth || 640,
        videoRef.current?.videoHeight || 480
      );
      if (box.width < minSize * 0.25 || box.height < minSize * 0.25) {
        return { ok: false, reason: "face-too-small" };
      }

      vecs.push(det.descriptor);

      if (i < samples - 1) {
        await new Promise((r) => setTimeout(r, gapMs));
      }
    }

    // average the vectors
    const len = vecs[0].length;
    const avg = new Float32Array(len).fill(0);
    vecs.forEach((v) => {
      for (let i = 0; i < len; i++) avg[i] += v[i];
    });
    for (let i = 0; i < len; i++) avg[i] /= samples;

    return { ok: true, descriptor: Array.from(avg) };
  };

  const handleAttendance = async () => {
    // prevent overlapping runs
    if (runningDetection.current) return;
    runningDetection.current = true;
    setLoading(true);

    try {
      if (!modelsLoaded || !videoReady) {
        console.warn("Models/video not ready yet");
        return;
      }

      // quick check: exactly one face in frame
      const multi = await faceapi
        .detectAllFaces(
          videoRef.current,
          new faceapi.TinyFaceDetectorOptions({ inputSize: 224, scoreThreshold: 0.6 })
        )
        .withFaceLandmarks();

      if (!multi || multi.length === 0) {
        console.warn("‚ö†Ô∏è No face detected");
        setShowPopup(true);
        return;
      }
      if (multi.length > 1) {
        console.warn("‚ö†Ô∏è Multiple faces detected ‚Äî rejecting for safety");
        setShowPopup(true);
        return;
      }

      // Stabilize: average 3 descriptors
      const stab = await getAveragedDescriptor(3, 150);
      if (!stab.ok) {
        console.warn("Descriptor stabilization failed:", stab.reason);
        setShowPopup(true);
        return;
      }

      const descriptor = stab.descriptor;
      const imageData = captureImage();

      const res = await fetch("/api/verify-face", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        // NOTE: send the averaged descriptor; server should return { success, user, distance }
        body: JSON.stringify({ descriptor }),
      });

      const result = await res.json();
      console.log("üíª Verification result:", result);

      // Enforce a strict distance threshold on the client too (extra guard)
      const serverDistance =
        typeof result?.distance === "number"
          ? result.distance
          : typeof result?.matchDistance === "number"
          ? result.matchDistance
          : null;

      const distanceOk = serverDistance === null ? true : serverDistance < 0.45;

      if (result.success && result.user && distanceOk) {
        const { name, role, userId, imageUrl } = result.user;

        localStorage.setItem("uid", userId);

        // Optional: notify Telegram (ignore errors)
        fetch("/api/send-telegram", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ name, role, userId, imageData }),
        }).catch(() => {});

        // Navigate only on confident match
        router.push(
          `/success?name=${encodeURIComponent(name)}&role=${encodeURIComponent(
            role
          )}&userId=${encodeURIComponent(userId)}&image=${encodeURIComponent(
            imageUrl || ""
          )}&imageData=${encodeURIComponent(imageData)}`
        );
      } else {
        console.warn("‚ö†Ô∏è User not recognized or distance too high", {
          serverDistance,
        });
        setShowPopup(true);
      }
    } catch (err) {
      console.error("Error during face recognition:", err);
      alert("Error occurred during attendance.");
    } finally {
      setLoading(false);
      runningDetection.current = false;
    }
  };

  // Auto-detect every 2.5s but never overlap; pause when popup is open
  useEffect(() => {
    if (!modelsLoaded || !videoReady) return;
    if (detectTimer.current) clearInterval(detectTimer.current);

    detectTimer.current = setInterval(() => {
      if (!loading && !showPopup && document.visibilityState === "visible") {
        handleAttendance();
      }
    }, 2500);

    return () => {
      if (detectTimer.current) clearInterval(detectTimer.current);
    };
  }, [modelsLoaded, videoReady, loading, showPopup]);

  return (
    <main className="h-screen w-screen flex flex-col items-center justify-center bg-gradient-to-b from-gray-50 to-gray-200 p-6 text-center relative">
      {/* Popup */}
      {showPopup && (
        <div className="fixed inset-0 flex items-center justify-center bg-black/50 z-50">
          <div className="bg-white p-6 rounded-2xl shadow-lg w-80 relative">
            <button
              onClick={handleClose}
              className="absolute top-2 right-2 text-gray-500 hover:text-red-500 text-lg"
            >
              ‚úï
            </button>
            <h2 className="text-xl font-bold text-gray-800 mb-2">Welcome!</h2>
            <p className="text-gray-600 mb-4">
              Not recognized with high confidence.
              <br />
              Please choose your option:
            </p>
            <div className="flex gap-3">
              <Link href="/newStudent" className="flex-1">
                <button className="w-full bg-blue-600 text-white py-2 rounded-lg hover:bg-blue-700 transition">
                  New Student
                </button>
              </Link>
              <button
                onClick={handleClose}
                className="flex-1 bg-gray-300 py-2 rounded-lg hover:bg-gray-400 transition"
              >
                Already Registered
              </button>
            </div>
          </div>
        </div>
      )}

      {/* Logo */}
      <img
        src="/DesinerzAcademyDark.png"
        alt="Logo"
        className="w-100 h-auto mb-4 drop-shadow-lg"
      />

      {/* Camera Feed with Loader */}
      <div className="relative w-64 h-64 rounded-full overflow-hidden border-4 border-blue-500 shadow-lg mb-4 flex items-center justify-center">
        <video
          ref={videoRef}
          autoPlay
          playsInline
          muted
          className="w-full h-full object-cover rounded-full"
        />
        {loading && (
          <div className="absolute inset-0 flex items-center justify-center">
            <div className="relative w-72 h-72 flex items-center justify-center">
              <span className="absolute w-64 h-64 rounded-full border-4 border-white animate-border-pulse"></span>
            </div>
          </div>
        )}
      </div>

      <h1 className="text-3xl font-extrabold text-gray-800 mb-6 leading-snug">
        Welcome <br /> to <br /> MDCI
      </h1>

      <button
        onClick={handleAttendance}
        disabled={loading || !modelsLoaded || !videoReady}
        className="bg-green-600 text-white px-6 py-3 rounded-lg text-lg shadow hover:bg-green-700 transition disabled:bg-green-400 mb-4"
      >
        {loading ? "Detecting..." : "Mark Your Daily Attendance"}
      </button>

      {!isInstalled && installPrompt && (
        <button
          onClick={handleInstall}
          className="bg-indigo-600 text-white px-5 py-2 rounded-lg shadow hover:bg-indigo-700 transition"
        >
          Install App
        </button>
      )}
    </main>
  );
}
